dataset:
    name: dataset:Clouds # required format: <module_name>:<object_name>
    classes: ['CLEAR', 'CLOUD']
    label_colors: [[0, 0, 0], [255, 255, 255]]
    params:
        # data_folder: /Volumes/MAGNUS_USB/Zaitra_Challenge/data
        # data_folder: /Midgard/Data/tibbe/datasets/Sentinel2
        data_folder: /local_storage/users/tibbe/datasets/Sentinel2
        scenes_folder: subscenes
        masks_folder: masks
        image_size: 224
        overlap: 30
    train_params:
        transform: scripts.transforms:TrainTransform # required format: <module_name>:<object_name>
        split: train
    val_params:
        transform: scripts.transforms:ValTransform # required format: <module_name>:<object_name>
        split: val
    test_params:
        transform: scripts.transforms:ValTransform # required format: <module_name>:<object_name>
        split: test
model:
    name: scripts.model:CloudSegmentationModel # required format: <module_name>:<object_name>
    load_weights:
        enable: false
        path: model/DeepLabv3_best.pth
    in_params:
        in_channels: 4
        num_classes: 2
hparams:
    epochs: 60
    batch_size: 1
    save_best_threshold: 0.3
    visualize_interval: 1
    criterion:
        name: torch.nn:CrossEntropyLoss  # scripts.loss:DiceBCELoss # required format: <module_name>:<object_name>
        in_params: {}
    optimizer: 
        name: torch.optim:Adam
        in_params:
            lr: 0.01
    scheduler:
        enable: true
        name: torch.optim.lr_scheduler:ReduceLROnPlateau
        in_params:
            factor: 0.5
            mode: min
            min_lr: 0.00001
wandb:
    enable: false
    project_name: zaitra_challenge_lrs
    run_name: DeepLabv3_ReduceLROnPlateau
outputs:
    train_results:  outputs/train_results
    model: outputs/model
    # model: /local_storage/users/tibbe/Zaitra_Challenge/model
    test: outputs/test
